{"version":3,"file":"vendors-node_modules_monaco-editor_esm_vs_editor_common_services_semanticTokensProviderStyling_js.bundle.js","mappings":";;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,uCAAuC,SAAS;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,sBAAsB;AACrD;AACA,0CAA0C;AAC1C;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,gBAAgB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC5EA;AACA;AACA;AACA;AAC0F;AACnF,yBAAyB,gGAAe;;;;;;;;;;;;;;;;;;;;;ACL/C;AACA;AACA;AACA;AACA,kBAAkB,SAAI,IAAI,SAAI;AAC9B;AACA;AACA,6CAA6C,QAAQ;AACrD;AACA;AACA,eAAe,SAAI,IAAI,SAAI;AAC3B,oCAAoC;AACpC;AAC6D;AACkB;AACH;AACD;AACf;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,iEAAQ;AACxE,iFAAiF,gBAAgB,IAAI,iBAAiB,eAAe,qEAAa,yBAAyB,cAAc,qEAAa,oCAAoC;AAC1O;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,uEAAuE;AACnH;AACA;AACA;AACA;AACA;AACA,uFAAuF,iEAAQ;AAC/F,2GAA2G,8BAA8B,cAAc,4CAA4C;AACnM;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oEAAoE,iEAAQ;AAC5E,uGAAuG,gBAAgB,cAAc,wCAAwC;AAC7K;AACA;AACA;AACA;AACA;AACA,gEAAgE,iEAAQ;AACxE,wEAAwE,gBAAgB,GAAG,UAAU,MAAM,kBAAkB,GAAG,yBAAyB,gBAAgB,qEAAa,yBAAyB,cAAc,qEAAa,oCAAoC;AAC9Q;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wFAAwF,WAAW,WAAW,YAAY;AAC1H;AACA;AACA;AACA;AACA;AACA,+FAA+F,WAAW,WAAW,YAAY;AACjI;AACA;AACA;AACA;AACA;AACA,8FAA8F,iBAAiB,cAAc,SAAS,aAAa,UAAU,8BAA8B,WAAW,uCAAuC,iBAAiB;AAC9P;AACA;AACA;AACA;AACA,eAAe,iFAAa;AAC5B,eAAe,oEAAgB;AAC/B,eAAe,oEAAW;AAC1B;AACyC;AAClC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,mFAAqB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACnRA;AACA;AACA;AACA;AAC+C;AACN;AACQ;AACjD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iDAAK;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,6DAAQ;AACpE;AACA;AACA;AACA;AACA,mCAAmC,uDAAQ;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C,4BAA4B,wCAAwC,GAAG,2BAA2B,GAAG,yBAAyB;AAC9H;AACA,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iDAAK;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://localwebeditor/./node_modules/monaco-editor/esm/vs/editor/common/core/eolCounter.js","webpack://localwebeditor/./node_modules/monaco-editor/esm/vs/editor/common/encodedTokenAttributes.js","webpack://localwebeditor/./node_modules/monaco-editor/esm/vs/editor/common/languages/language.js","webpack://localwebeditor/./node_modules/monaco-editor/esm/vs/editor/common/services/semanticTokensProviderStyling.js","webpack://localwebeditor/./node_modules/monaco-editor/esm/vs/editor/common/tokens/sparseMultilineTokens.js"],"sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nexport function countEOL(text) {\n    let eolCount = 0;\n    let firstLineLength = 0;\n    let lastLineStart = 0;\n    let eol = 0 /* StringEOL.Unknown */;\n    for (let i = 0, len = text.length; i < len; i++) {\n        const chr = text.charCodeAt(i);\n        if (chr === 13 /* CharCode.CarriageReturn */) {\n            if (eolCount === 0) {\n                firstLineLength = i;\n            }\n            eolCount++;\n            if (i + 1 < len && text.charCodeAt(i + 1) === 10 /* CharCode.LineFeed */) {\n                // \\r\\n... case\n                eol |= 2 /* StringEOL.CRLF */;\n                i++; // skip \\n\n            }\n            else {\n                // \\r... case\n                eol |= 3 /* StringEOL.Invalid */;\n            }\n            lastLineStart = i + 1;\n        }\n        else if (chr === 10 /* CharCode.LineFeed */) {\n            // \\n... case\n            eol |= 1 /* StringEOL.LF */;\n            if (eolCount === 0) {\n                firstLineLength = i;\n            }\n            eolCount++;\n            lastLineStart = i + 1;\n        }\n    }\n    if (eolCount === 0) {\n        firstLineLength = text.length;\n    }\n    return [eolCount, firstLineLength, text.length - lastLineStart, eol];\n}\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n/**\n */\nexport class TokenMetadata {\n    static getLanguageId(metadata) {\n        return (metadata & 255 /* MetadataConsts.LANGUAGEID_MASK */) >>> 0 /* MetadataConsts.LANGUAGEID_OFFSET */;\n    }\n    static getTokenType(metadata) {\n        return (metadata & 768 /* MetadataConsts.TOKEN_TYPE_MASK */) >>> 8 /* MetadataConsts.TOKEN_TYPE_OFFSET */;\n    }\n    static containsBalancedBrackets(metadata) {\n        return (metadata & 1024 /* MetadataConsts.BALANCED_BRACKETS_MASK */) !== 0;\n    }\n    static getFontStyle(metadata) {\n        return (metadata & 30720 /* MetadataConsts.FONT_STYLE_MASK */) >>> 11 /* MetadataConsts.FONT_STYLE_OFFSET */;\n    }\n    static getForeground(metadata) {\n        return (metadata & 16744448 /* MetadataConsts.FOREGROUND_MASK */) >>> 15 /* MetadataConsts.FOREGROUND_OFFSET */;\n    }\n    static getBackground(metadata) {\n        return (metadata & 4278190080 /* MetadataConsts.BACKGROUND_MASK */) >>> 24 /* MetadataConsts.BACKGROUND_OFFSET */;\n    }\n    static getClassNameFromMetadata(metadata) {\n        const foreground = this.getForeground(metadata);\n        let className = 'mtk' + foreground;\n        const fontStyle = this.getFontStyle(metadata);\n        if (fontStyle & 1 /* FontStyle.Italic */) {\n            className += ' mtki';\n        }\n        if (fontStyle & 2 /* FontStyle.Bold */) {\n            className += ' mtkb';\n        }\n        if (fontStyle & 4 /* FontStyle.Underline */) {\n            className += ' mtku';\n        }\n        if (fontStyle & 8 /* FontStyle.Strikethrough */) {\n            className += ' mtks';\n        }\n        return className;\n    }\n    static getInlineStyleFromMetadata(metadata, colorMap) {\n        const foreground = this.getForeground(metadata);\n        const fontStyle = this.getFontStyle(metadata);\n        let result = `color: ${colorMap[foreground]};`;\n        if (fontStyle & 1 /* FontStyle.Italic */) {\n            result += 'font-style: italic;';\n        }\n        if (fontStyle & 2 /* FontStyle.Bold */) {\n            result += 'font-weight: bold;';\n        }\n        let textDecoration = '';\n        if (fontStyle & 4 /* FontStyle.Underline */) {\n            textDecoration += ' underline';\n        }\n        if (fontStyle & 8 /* FontStyle.Strikethrough */) {\n            textDecoration += ' line-through';\n        }\n        if (textDecoration) {\n            result += `text-decoration:${textDecoration};`;\n        }\n        return result;\n    }\n    static getPresentationFromMetadata(metadata) {\n        const foreground = this.getForeground(metadata);\n        const fontStyle = this.getFontStyle(metadata);\n        return {\n            foreground: foreground,\n            italic: Boolean(fontStyle & 1 /* FontStyle.Italic */),\n            bold: Boolean(fontStyle & 2 /* FontStyle.Bold */),\n            underline: Boolean(fontStyle & 4 /* FontStyle.Underline */),\n            strikethrough: Boolean(fontStyle & 8 /* FontStyle.Strikethrough */),\n        };\n    }\n}\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport { createDecorator } from '../../../platform/instantiation/common/instantiation.js';\nexport const ILanguageService = createDecorator('languageService');\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __param = (this && this.__param) || function (paramIndex, decorator) {\n    return function (target, key) { decorator(target, key, paramIndex); }\n};\nimport { TokenMetadata } from '../encodedTokenAttributes.js';\nimport { IThemeService } from '../../../platform/theme/common/themeService.js';\nimport { ILogService, LogLevel } from '../../../platform/log/common/log.js';\nimport { SparseMultilineTokens } from '../tokens/sparseMultilineTokens.js';\nimport { ILanguageService } from '../languages/language.js';\nconst ENABLE_TRACE = false;\nlet SemanticTokensProviderStyling = class SemanticTokensProviderStyling {\n    constructor(_legend, _themeService, _languageService, _logService) {\n        this._legend = _legend;\n        this._themeService = _themeService;\n        this._languageService = _languageService;\n        this._logService = _logService;\n        this._hasWarnedOverlappingTokens = false;\n        this._hasWarnedInvalidLengthTokens = false;\n        this._hasWarnedInvalidEditStart = false;\n        this._hashTable = new HashTable();\n    }\n    getMetadata(tokenTypeIndex, tokenModifierSet, languageId) {\n        const encodedLanguageId = this._languageService.languageIdCodec.encodeLanguageId(languageId);\n        const entry = this._hashTable.get(tokenTypeIndex, tokenModifierSet, encodedLanguageId);\n        let metadata;\n        if (entry) {\n            metadata = entry.metadata;\n            if (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n                this._logService.trace(`SemanticTokensProviderStyling [CACHED] ${tokenTypeIndex} / ${tokenModifierSet}: foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`);\n            }\n        }\n        else {\n            let tokenType = this._legend.tokenTypes[tokenTypeIndex];\n            const tokenModifiers = [];\n            if (tokenType) {\n                let modifierSet = tokenModifierSet;\n                for (let modifierIndex = 0; modifierSet > 0 && modifierIndex < this._legend.tokenModifiers.length; modifierIndex++) {\n                    if (modifierSet & 1) {\n                        tokenModifiers.push(this._legend.tokenModifiers[modifierIndex]);\n                    }\n                    modifierSet = modifierSet >> 1;\n                }\n                if (ENABLE_TRACE && modifierSet > 0 && this._logService.getLevel() === LogLevel.Trace) {\n                    this._logService.trace(`SemanticTokensProviderStyling: unknown token modifier index: ${tokenModifierSet.toString(2)} for legend: ${JSON.stringify(this._legend.tokenModifiers)}`);\n                    tokenModifiers.push('not-in-legend');\n                }\n                const tokenStyle = this._themeService.getColorTheme().getTokenStyleMetadata(tokenType, tokenModifiers, languageId);\n                if (typeof tokenStyle === 'undefined') {\n                    metadata = 2147483647 /* SemanticTokensProviderStylingConstants.NO_STYLING */;\n                }\n                else {\n                    metadata = 0;\n                    if (typeof tokenStyle.italic !== 'undefined') {\n                        const italicBit = (tokenStyle.italic ? 1 /* FontStyle.Italic */ : 0) << 11 /* MetadataConsts.FONT_STYLE_OFFSET */;\n                        metadata |= italicBit | 1 /* MetadataConsts.SEMANTIC_USE_ITALIC */;\n                    }\n                    if (typeof tokenStyle.bold !== 'undefined') {\n                        const boldBit = (tokenStyle.bold ? 2 /* FontStyle.Bold */ : 0) << 11 /* MetadataConsts.FONT_STYLE_OFFSET */;\n                        metadata |= boldBit | 2 /* MetadataConsts.SEMANTIC_USE_BOLD */;\n                    }\n                    if (typeof tokenStyle.underline !== 'undefined') {\n                        const underlineBit = (tokenStyle.underline ? 4 /* FontStyle.Underline */ : 0) << 11 /* MetadataConsts.FONT_STYLE_OFFSET */;\n                        metadata |= underlineBit | 4 /* MetadataConsts.SEMANTIC_USE_UNDERLINE */;\n                    }\n                    if (typeof tokenStyle.strikethrough !== 'undefined') {\n                        const strikethroughBit = (tokenStyle.strikethrough ? 8 /* FontStyle.Strikethrough */ : 0) << 11 /* MetadataConsts.FONT_STYLE_OFFSET */;\n                        metadata |= strikethroughBit | 8 /* MetadataConsts.SEMANTIC_USE_STRIKETHROUGH */;\n                    }\n                    if (tokenStyle.foreground) {\n                        const foregroundBits = (tokenStyle.foreground) << 15 /* MetadataConsts.FOREGROUND_OFFSET */;\n                        metadata |= foregroundBits | 16 /* MetadataConsts.SEMANTIC_USE_FOREGROUND */;\n                    }\n                    if (metadata === 0) {\n                        // Nothing!\n                        metadata = 2147483647 /* SemanticTokensProviderStylingConstants.NO_STYLING */;\n                    }\n                }\n            }\n            else {\n                if (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n                    this._logService.trace(`SemanticTokensProviderStyling: unknown token type index: ${tokenTypeIndex} for legend: ${JSON.stringify(this._legend.tokenTypes)}`);\n                }\n                metadata = 2147483647 /* SemanticTokensProviderStylingConstants.NO_STYLING */;\n                tokenType = 'not-in-legend';\n            }\n            this._hashTable.add(tokenTypeIndex, tokenModifierSet, encodedLanguageId, metadata);\n            if (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n                this._logService.trace(`SemanticTokensProviderStyling ${tokenTypeIndex} (${tokenType}) / ${tokenModifierSet} (${tokenModifiers.join(' ')}): foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`);\n            }\n        }\n        return metadata;\n    }\n    warnOverlappingSemanticTokens(lineNumber, startColumn) {\n        if (!this._hasWarnedOverlappingTokens) {\n            this._hasWarnedOverlappingTokens = true;\n            this._logService.warn(`Overlapping semantic tokens detected at lineNumber ${lineNumber}, column ${startColumn}`);\n        }\n    }\n    warnInvalidLengthSemanticTokens(lineNumber, startColumn) {\n        if (!this._hasWarnedInvalidLengthTokens) {\n            this._hasWarnedInvalidLengthTokens = true;\n            this._logService.warn(`Semantic token with invalid length detected at lineNumber ${lineNumber}, column ${startColumn}`);\n        }\n    }\n    warnInvalidEditStart(previousResultId, resultId, editIndex, editStart, maxExpectedStart) {\n        if (!this._hasWarnedInvalidEditStart) {\n            this._hasWarnedInvalidEditStart = true;\n            this._logService.warn(`Invalid semantic tokens edit detected (previousResultId: ${previousResultId}, resultId: ${resultId}) at edit #${editIndex}: The provided start offset ${editStart} is outside the previous data (length ${maxExpectedStart}).`);\n        }\n    }\n};\nSemanticTokensProviderStyling = __decorate([\n    __param(1, IThemeService),\n    __param(2, ILanguageService),\n    __param(3, ILogService)\n], SemanticTokensProviderStyling);\nexport { SemanticTokensProviderStyling };\nexport function toMultilineTokens2(tokens, styling, languageId) {\n    const srcData = tokens.data;\n    const tokenCount = (tokens.data.length / 5) | 0;\n    const tokensPerArea = Math.max(Math.ceil(tokenCount / 1024 /* SemanticColoringConstants.DesiredMaxAreas */), 400 /* SemanticColoringConstants.DesiredTokensPerArea */);\n    const result = [];\n    let tokenIndex = 0;\n    let lastLineNumber = 1;\n    let lastStartCharacter = 0;\n    while (tokenIndex < tokenCount) {\n        const tokenStartIndex = tokenIndex;\n        let tokenEndIndex = Math.min(tokenStartIndex + tokensPerArea, tokenCount);\n        // Keep tokens on the same line in the same area...\n        if (tokenEndIndex < tokenCount) {\n            let smallTokenEndIndex = tokenEndIndex;\n            while (smallTokenEndIndex - 1 > tokenStartIndex && srcData[5 * smallTokenEndIndex] === 0) {\n                smallTokenEndIndex--;\n            }\n            if (smallTokenEndIndex - 1 === tokenStartIndex) {\n                // there are so many tokens on this line that our area would be empty, we must now go right\n                let bigTokenEndIndex = tokenEndIndex;\n                while (bigTokenEndIndex + 1 < tokenCount && srcData[5 * bigTokenEndIndex] === 0) {\n                    bigTokenEndIndex++;\n                }\n                tokenEndIndex = bigTokenEndIndex;\n            }\n            else {\n                tokenEndIndex = smallTokenEndIndex;\n            }\n        }\n        let destData = new Uint32Array((tokenEndIndex - tokenStartIndex) * 4);\n        let destOffset = 0;\n        let areaLine = 0;\n        let prevLineNumber = 0;\n        let prevEndCharacter = 0;\n        while (tokenIndex < tokenEndIndex) {\n            const srcOffset = 5 * tokenIndex;\n            const deltaLine = srcData[srcOffset];\n            const deltaCharacter = srcData[srcOffset + 1];\n            // Casting both `lineNumber`, `startCharacter` and `endCharacter` here to uint32 using `|0`\n            // to validate below with the actual values that will be inserted in the Uint32Array result\n            const lineNumber = (lastLineNumber + deltaLine) | 0;\n            const startCharacter = (deltaLine === 0 ? (lastStartCharacter + deltaCharacter) | 0 : deltaCharacter);\n            const length = srcData[srcOffset + 2];\n            const endCharacter = (startCharacter + length) | 0;\n            const tokenTypeIndex = srcData[srcOffset + 3];\n            const tokenModifierSet = srcData[srcOffset + 4];\n            if (endCharacter <= startCharacter) {\n                // this token is invalid (most likely a negative length casted to uint32)\n                styling.warnInvalidLengthSemanticTokens(lineNumber, startCharacter + 1);\n            }\n            else if (prevLineNumber === lineNumber && prevEndCharacter > startCharacter) {\n                // this token overlaps with the previous token\n                styling.warnOverlappingSemanticTokens(lineNumber, startCharacter + 1);\n            }\n            else {\n                const metadata = styling.getMetadata(tokenTypeIndex, tokenModifierSet, languageId);\n                if (metadata !== 2147483647 /* SemanticTokensProviderStylingConstants.NO_STYLING */) {\n                    if (areaLine === 0) {\n                        areaLine = lineNumber;\n                    }\n                    destData[destOffset] = lineNumber - areaLine;\n                    destData[destOffset + 1] = startCharacter;\n                    destData[destOffset + 2] = endCharacter;\n                    destData[destOffset + 3] = metadata;\n                    destOffset += 4;\n                    prevLineNumber = lineNumber;\n                    prevEndCharacter = endCharacter;\n                }\n            }\n            lastLineNumber = lineNumber;\n            lastStartCharacter = startCharacter;\n            tokenIndex++;\n        }\n        if (destOffset !== destData.length) {\n            destData = destData.subarray(0, destOffset);\n        }\n        const tokens = SparseMultilineTokens.create(areaLine, destData);\n        result.push(tokens);\n    }\n    return result;\n}\nclass HashTableEntry {\n    constructor(tokenTypeIndex, tokenModifierSet, languageId, metadata) {\n        this.tokenTypeIndex = tokenTypeIndex;\n        this.tokenModifierSet = tokenModifierSet;\n        this.languageId = languageId;\n        this.metadata = metadata;\n        this.next = null;\n    }\n}\nclass HashTable {\n    static { this._SIZES = [3, 7, 13, 31, 61, 127, 251, 509, 1021, 2039, 4093, 8191, 16381, 32749, 65521, 131071, 262139, 524287, 1048573, 2097143]; }\n    constructor() {\n        this._elementsCount = 0;\n        this._currentLengthIndex = 0;\n        this._currentLength = HashTable._SIZES[this._currentLengthIndex];\n        this._growCount = Math.round(this._currentLengthIndex + 1 < HashTable._SIZES.length ? 2 / 3 * this._currentLength : 0);\n        this._elements = [];\n        HashTable._nullOutEntries(this._elements, this._currentLength);\n    }\n    static _nullOutEntries(entries, length) {\n        for (let i = 0; i < length; i++) {\n            entries[i] = null;\n        }\n    }\n    _hash2(n1, n2) {\n        return (((n1 << 5) - n1) + n2) | 0; // n1 * 31 + n2, keep as int32\n    }\n    _hashFunc(tokenTypeIndex, tokenModifierSet, languageId) {\n        return this._hash2(this._hash2(tokenTypeIndex, tokenModifierSet), languageId) % this._currentLength;\n    }\n    get(tokenTypeIndex, tokenModifierSet, languageId) {\n        const hash = this._hashFunc(tokenTypeIndex, tokenModifierSet, languageId);\n        let p = this._elements[hash];\n        while (p) {\n            if (p.tokenTypeIndex === tokenTypeIndex && p.tokenModifierSet === tokenModifierSet && p.languageId === languageId) {\n                return p;\n            }\n            p = p.next;\n        }\n        return null;\n    }\n    add(tokenTypeIndex, tokenModifierSet, languageId, metadata) {\n        this._elementsCount++;\n        if (this._growCount !== 0 && this._elementsCount >= this._growCount) {\n            // expand!\n            const oldElements = this._elements;\n            this._currentLengthIndex++;\n            this._currentLength = HashTable._SIZES[this._currentLengthIndex];\n            this._growCount = Math.round(this._currentLengthIndex + 1 < HashTable._SIZES.length ? 2 / 3 * this._currentLength : 0);\n            this._elements = [];\n            HashTable._nullOutEntries(this._elements, this._currentLength);\n            for (const first of oldElements) {\n                let p = first;\n                while (p) {\n                    const oldNext = p.next;\n                    p.next = null;\n                    this._add(p);\n                    p = oldNext;\n                }\n            }\n        }\n        this._add(new HashTableEntry(tokenTypeIndex, tokenModifierSet, languageId, metadata));\n    }\n    _add(element) {\n        const hash = this._hashFunc(element.tokenTypeIndex, element.tokenModifierSet, element.languageId);\n        element.next = this._elements[hash];\n        this._elements[hash] = element;\n    }\n}\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport { Position } from '../core/position.js';\nimport { Range } from '../core/range.js';\nimport { countEOL } from '../core/eolCounter.js';\n/**\n * Represents sparse tokens over a contiguous range of lines.\n */\nexport class SparseMultilineTokens {\n    static create(startLineNumber, tokens) {\n        return new SparseMultilineTokens(startLineNumber, new SparseMultilineTokensStorage(tokens));\n    }\n    /**\n     * (Inclusive) start line number for these tokens.\n     */\n    get startLineNumber() {\n        return this._startLineNumber;\n    }\n    /**\n     * (Inclusive) end line number for these tokens.\n     */\n    get endLineNumber() {\n        return this._endLineNumber;\n    }\n    constructor(startLineNumber, tokens) {\n        this._startLineNumber = startLineNumber;\n        this._tokens = tokens;\n        this._endLineNumber = this._startLineNumber + this._tokens.getMaxDeltaLine();\n    }\n    toString() {\n        return this._tokens.toString(this._startLineNumber);\n    }\n    _updateEndLineNumber() {\n        this._endLineNumber = this._startLineNumber + this._tokens.getMaxDeltaLine();\n    }\n    isEmpty() {\n        return this._tokens.isEmpty();\n    }\n    getLineTokens(lineNumber) {\n        if (this._startLineNumber <= lineNumber && lineNumber <= this._endLineNumber) {\n            return this._tokens.getLineTokens(lineNumber - this._startLineNumber);\n        }\n        return null;\n    }\n    getRange() {\n        const deltaRange = this._tokens.getRange();\n        if (!deltaRange) {\n            return deltaRange;\n        }\n        return new Range(this._startLineNumber + deltaRange.startLineNumber, deltaRange.startColumn, this._startLineNumber + deltaRange.endLineNumber, deltaRange.endColumn);\n    }\n    removeTokens(range) {\n        const startLineIndex = range.startLineNumber - this._startLineNumber;\n        const endLineIndex = range.endLineNumber - this._startLineNumber;\n        this._startLineNumber += this._tokens.removeTokens(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1);\n        this._updateEndLineNumber();\n    }\n    split(range) {\n        // split tokens to two:\n        // a) all the tokens before `range`\n        // b) all the tokens after `range`\n        const startLineIndex = range.startLineNumber - this._startLineNumber;\n        const endLineIndex = range.endLineNumber - this._startLineNumber;\n        const [a, b, bDeltaLine] = this._tokens.split(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1);\n        return [new SparseMultilineTokens(this._startLineNumber, a), new SparseMultilineTokens(this._startLineNumber + bDeltaLine, b)];\n    }\n    applyEdit(range, text) {\n        const [eolCount, firstLineLength, lastLineLength] = countEOL(text);\n        this.acceptEdit(range, eolCount, firstLineLength, lastLineLength, text.length > 0 ? text.charCodeAt(0) : 0 /* CharCode.Null */);\n    }\n    acceptEdit(range, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        this._acceptDeleteRange(range);\n        this._acceptInsertText(new Position(range.startLineNumber, range.startColumn), eolCount, firstLineLength, lastLineLength, firstCharCode);\n        this._updateEndLineNumber();\n    }\n    _acceptDeleteRange(range) {\n        if (range.startLineNumber === range.endLineNumber && range.startColumn === range.endColumn) {\n            // Nothing to delete\n            return;\n        }\n        const firstLineIndex = range.startLineNumber - this._startLineNumber;\n        const lastLineIndex = range.endLineNumber - this._startLineNumber;\n        if (lastLineIndex < 0) {\n            // this deletion occurs entirely before this block, so we only need to adjust line numbers\n            const deletedLinesCount = lastLineIndex - firstLineIndex;\n            this._startLineNumber -= deletedLinesCount;\n            return;\n        }\n        const tokenMaxDeltaLine = this._tokens.getMaxDeltaLine();\n        if (firstLineIndex >= tokenMaxDeltaLine + 1) {\n            // this deletion occurs entirely after this block, so there is nothing to do\n            return;\n        }\n        if (firstLineIndex < 0 && lastLineIndex >= tokenMaxDeltaLine + 1) {\n            // this deletion completely encompasses this block\n            this._startLineNumber = 0;\n            this._tokens.clear();\n            return;\n        }\n        if (firstLineIndex < 0) {\n            const deletedBefore = -firstLineIndex;\n            this._startLineNumber -= deletedBefore;\n            this._tokens.acceptDeleteRange(range.startColumn - 1, 0, 0, lastLineIndex, range.endColumn - 1);\n        }\n        else {\n            this._tokens.acceptDeleteRange(0, firstLineIndex, range.startColumn - 1, lastLineIndex, range.endColumn - 1);\n        }\n    }\n    _acceptInsertText(position, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        if (eolCount === 0 && firstLineLength === 0) {\n            // Nothing to insert\n            return;\n        }\n        const lineIndex = position.lineNumber - this._startLineNumber;\n        if (lineIndex < 0) {\n            // this insertion occurs before this block, so we only need to adjust line numbers\n            this._startLineNumber += eolCount;\n            return;\n        }\n        const tokenMaxDeltaLine = this._tokens.getMaxDeltaLine();\n        if (lineIndex >= tokenMaxDeltaLine + 1) {\n            // this insertion occurs after this block, so there is nothing to do\n            return;\n        }\n        this._tokens.acceptInsertText(lineIndex, position.column - 1, eolCount, firstLineLength, lastLineLength, firstCharCode);\n    }\n}\nclass SparseMultilineTokensStorage {\n    constructor(tokens) {\n        this._tokens = tokens;\n        this._tokenCount = tokens.length / 4;\n    }\n    toString(startLineNumber) {\n        const pieces = [];\n        for (let i = 0; i < this._tokenCount; i++) {\n            pieces.push(`(${this._getDeltaLine(i) + startLineNumber},${this._getStartCharacter(i)}-${this._getEndCharacter(i)})`);\n        }\n        return `[${pieces.join(',')}]`;\n    }\n    getMaxDeltaLine() {\n        const tokenCount = this._getTokenCount();\n        if (tokenCount === 0) {\n            return -1;\n        }\n        return this._getDeltaLine(tokenCount - 1);\n    }\n    getRange() {\n        const tokenCount = this._getTokenCount();\n        if (tokenCount === 0) {\n            return null;\n        }\n        const startChar = this._getStartCharacter(0);\n        const maxDeltaLine = this._getDeltaLine(tokenCount - 1);\n        const endChar = this._getEndCharacter(tokenCount - 1);\n        return new Range(0, startChar + 1, maxDeltaLine, endChar + 1);\n    }\n    _getTokenCount() {\n        return this._tokenCount;\n    }\n    _getDeltaLine(tokenIndex) {\n        return this._tokens[4 * tokenIndex];\n    }\n    _getStartCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 1];\n    }\n    _getEndCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 2];\n    }\n    isEmpty() {\n        return (this._getTokenCount() === 0);\n    }\n    getLineTokens(deltaLine) {\n        let low = 0;\n        let high = this._getTokenCount() - 1;\n        while (low < high) {\n            const mid = low + Math.floor((high - low) / 2);\n            const midDeltaLine = this._getDeltaLine(mid);\n            if (midDeltaLine < deltaLine) {\n                low = mid + 1;\n            }\n            else if (midDeltaLine > deltaLine) {\n                high = mid - 1;\n            }\n            else {\n                let min = mid;\n                while (min > low && this._getDeltaLine(min - 1) === deltaLine) {\n                    min--;\n                }\n                let max = mid;\n                while (max < high && this._getDeltaLine(max + 1) === deltaLine) {\n                    max++;\n                }\n                return new SparseLineTokens(this._tokens.subarray(4 * min, 4 * max + 4));\n            }\n        }\n        if (this._getDeltaLine(low) === deltaLine) {\n            return new SparseLineTokens(this._tokens.subarray(4 * low, 4 * low + 4));\n        }\n        return null;\n    }\n    clear() {\n        this._tokenCount = 0;\n    }\n    removeTokens(startDeltaLine, startChar, endDeltaLine, endChar) {\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        let newTokenCount = 0;\n        let hasDeletedTokens = false;\n        let firstDeltaLine = 0;\n        for (let i = 0; i < tokenCount; i++) {\n            const srcOffset = 4 * i;\n            const tokenDeltaLine = tokens[srcOffset];\n            const tokenStartCharacter = tokens[srcOffset + 1];\n            const tokenEndCharacter = tokens[srcOffset + 2];\n            const tokenMetadata = tokens[srcOffset + 3];\n            if ((tokenDeltaLine > startDeltaLine || (tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar))\n                && (tokenDeltaLine < endDeltaLine || (tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar))) {\n                hasDeletedTokens = true;\n            }\n            else {\n                if (newTokenCount === 0) {\n                    firstDeltaLine = tokenDeltaLine;\n                }\n                if (hasDeletedTokens) {\n                    // must move the token to the left\n                    const destOffset = 4 * newTokenCount;\n                    tokens[destOffset] = tokenDeltaLine - firstDeltaLine;\n                    tokens[destOffset + 1] = tokenStartCharacter;\n                    tokens[destOffset + 2] = tokenEndCharacter;\n                    tokens[destOffset + 3] = tokenMetadata;\n                }\n                newTokenCount++;\n            }\n        }\n        this._tokenCount = newTokenCount;\n        return firstDeltaLine;\n    }\n    split(startDeltaLine, startChar, endDeltaLine, endChar) {\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        const aTokens = [];\n        const bTokens = [];\n        let destTokens = aTokens;\n        let destOffset = 0;\n        let destFirstDeltaLine = 0;\n        for (let i = 0; i < tokenCount; i++) {\n            const srcOffset = 4 * i;\n            const tokenDeltaLine = tokens[srcOffset];\n            const tokenStartCharacter = tokens[srcOffset + 1];\n            const tokenEndCharacter = tokens[srcOffset + 2];\n            const tokenMetadata = tokens[srcOffset + 3];\n            if ((tokenDeltaLine > startDeltaLine || (tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar))) {\n                if ((tokenDeltaLine < endDeltaLine || (tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar))) {\n                    // this token is touching the range\n                    continue;\n                }\n                else {\n                    // this token is after the range\n                    if (destTokens !== bTokens) {\n                        // this token is the first token after the range\n                        destTokens = bTokens;\n                        destOffset = 0;\n                        destFirstDeltaLine = tokenDeltaLine;\n                    }\n                }\n            }\n            destTokens[destOffset++] = tokenDeltaLine - destFirstDeltaLine;\n            destTokens[destOffset++] = tokenStartCharacter;\n            destTokens[destOffset++] = tokenEndCharacter;\n            destTokens[destOffset++] = tokenMetadata;\n        }\n        return [new SparseMultilineTokensStorage(new Uint32Array(aTokens)), new SparseMultilineTokensStorage(new Uint32Array(bTokens)), destFirstDeltaLine];\n    }\n    acceptDeleteRange(horizontalShiftForFirstLineTokens, startDeltaLine, startCharacter, endDeltaLine, endCharacter) {\n        // This is a bit complex, here are the cases I used to think about this:\n        //\n        // 1. The token starts before the deletion range\n        // 1a. The token is completely before the deletion range\n        //               -----------\n        //                          xxxxxxxxxxx\n        // 1b. The token starts before, the deletion range ends after the token\n        //               -----------\n        //                      xxxxxxxxxxx\n        // 1c. The token starts before, the deletion range ends precisely with the token\n        //               ---------------\n        //                      xxxxxxxx\n        // 1d. The token starts before, the deletion range is inside the token\n        //               ---------------\n        //                    xxxxx\n        //\n        // 2. The token starts at the same position with the deletion range\n        // 2a. The token starts at the same position, and ends inside the deletion range\n        //               -------\n        //               xxxxxxxxxxx\n        // 2b. The token starts at the same position, and ends at the same position as the deletion range\n        //               ----------\n        //               xxxxxxxxxx\n        // 2c. The token starts at the same position, and ends after the deletion range\n        //               -------------\n        //               xxxxxxx\n        //\n        // 3. The token starts inside the deletion range\n        // 3a. The token is inside the deletion range\n        //                -------\n        //             xxxxxxxxxxxxx\n        // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n        //                ----------\n        //             xxxxxxxxxxxxx\n        // 3c. The token starts inside the deletion range, and ends after the deletion range\n        //                ------------\n        //             xxxxxxxxxxx\n        //\n        // 4. The token starts after the deletion range\n        //                  -----------\n        //          xxxxxxxx\n        //\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        const deletedLineCount = (endDeltaLine - startDeltaLine);\n        let newTokenCount = 0;\n        let hasDeletedTokens = false;\n        for (let i = 0; i < tokenCount; i++) {\n            const srcOffset = 4 * i;\n            let tokenDeltaLine = tokens[srcOffset];\n            let tokenStartCharacter = tokens[srcOffset + 1];\n            let tokenEndCharacter = tokens[srcOffset + 2];\n            const tokenMetadata = tokens[srcOffset + 3];\n            if (tokenDeltaLine < startDeltaLine || (tokenDeltaLine === startDeltaLine && tokenEndCharacter <= startCharacter)) {\n                // 1a. The token is completely before the deletion range\n                // => nothing to do\n                newTokenCount++;\n                continue;\n            }\n            else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter < startCharacter) {\n                // 1b, 1c, 1d\n                // => the token survives, but it needs to shrink\n                if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n                    // 1d. The token starts before, the deletion range is inside the token\n                    // => the token shrinks by the deletion character count\n                    tokenEndCharacter -= (endCharacter - startCharacter);\n                }\n                else {\n                    // 1b. The token starts before, the deletion range ends after the token\n                    // 1c. The token starts before, the deletion range ends precisely with the token\n                    // => the token shrinks its ending to the deletion start\n                    tokenEndCharacter = startCharacter;\n                }\n            }\n            else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter === startCharacter) {\n                // 2a, 2b, 2c\n                if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n                    // 2c. The token starts at the same position, and ends after the deletion range\n                    // => the token shrinks by the deletion character count\n                    tokenEndCharacter -= (endCharacter - startCharacter);\n                }\n                else {\n                    // 2a. The token starts at the same position, and ends inside the deletion range\n                    // 2b. The token starts at the same position, and ends at the same position as the deletion range\n                    // => the token is deleted\n                    hasDeletedTokens = true;\n                    continue;\n                }\n            }\n            else if (tokenDeltaLine < endDeltaLine || (tokenDeltaLine === endDeltaLine && tokenStartCharacter < endCharacter)) {\n                // 3a, 3b, 3c\n                if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n                    // 3c. The token starts inside the deletion range, and ends after the deletion range\n                    // => the token moves to continue right after the deletion\n                    tokenDeltaLine = startDeltaLine;\n                    tokenStartCharacter = startCharacter;\n                    tokenEndCharacter = tokenStartCharacter + (tokenEndCharacter - endCharacter);\n                }\n                else {\n                    // 3a. The token is inside the deletion range\n                    // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n                    // => the token is deleted\n                    hasDeletedTokens = true;\n                    continue;\n                }\n            }\n            else if (tokenDeltaLine > endDeltaLine) {\n                // 4. (partial) The token starts after the deletion range, on a line below...\n                if (deletedLineCount === 0 && !hasDeletedTokens) {\n                    // early stop, there is no need to walk all the tokens and do nothing...\n                    newTokenCount = tokenCount;\n                    break;\n                }\n                tokenDeltaLine -= deletedLineCount;\n            }\n            else if (tokenDeltaLine === endDeltaLine && tokenStartCharacter >= endCharacter) {\n                // 4. (continued) The token starts after the deletion range, on the last line where a deletion occurs\n                if (horizontalShiftForFirstLineTokens && tokenDeltaLine === 0) {\n                    tokenStartCharacter += horizontalShiftForFirstLineTokens;\n                    tokenEndCharacter += horizontalShiftForFirstLineTokens;\n                }\n                tokenDeltaLine -= deletedLineCount;\n                tokenStartCharacter -= (endCharacter - startCharacter);\n                tokenEndCharacter -= (endCharacter - startCharacter);\n            }\n            else {\n                throw new Error(`Not possible!`);\n            }\n            const destOffset = 4 * newTokenCount;\n            tokens[destOffset] = tokenDeltaLine;\n            tokens[destOffset + 1] = tokenStartCharacter;\n            tokens[destOffset + 2] = tokenEndCharacter;\n            tokens[destOffset + 3] = tokenMetadata;\n            newTokenCount++;\n        }\n        this._tokenCount = newTokenCount;\n    }\n    acceptInsertText(deltaLine, character, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        // Here are the cases I used to think about this:\n        //\n        // 1. The token is completely before the insertion point\n        //            -----------   |\n        // 2. The token ends precisely at the insertion point\n        //            -----------|\n        // 3. The token contains the insertion point\n        //            -----|------\n        // 4. The token starts precisely at the insertion point\n        //            |-----------\n        // 5. The token is completely after the insertion point\n        //            |   -----------\n        //\n        const isInsertingPreciselyOneWordCharacter = (eolCount === 0\n            && firstLineLength === 1\n            && ((firstCharCode >= 48 /* CharCode.Digit0 */ && firstCharCode <= 57 /* CharCode.Digit9 */)\n                || (firstCharCode >= 65 /* CharCode.A */ && firstCharCode <= 90 /* CharCode.Z */)\n                || (firstCharCode >= 97 /* CharCode.a */ && firstCharCode <= 122 /* CharCode.z */)));\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        for (let i = 0; i < tokenCount; i++) {\n            const offset = 4 * i;\n            let tokenDeltaLine = tokens[offset];\n            let tokenStartCharacter = tokens[offset + 1];\n            let tokenEndCharacter = tokens[offset + 2];\n            if (tokenDeltaLine < deltaLine || (tokenDeltaLine === deltaLine && tokenEndCharacter < character)) {\n                // 1. The token is completely before the insertion point\n                // => nothing to do\n                continue;\n            }\n            else if (tokenDeltaLine === deltaLine && tokenEndCharacter === character) {\n                // 2. The token ends precisely at the insertion point\n                // => expand the end character only if inserting precisely one character that is a word character\n                if (isInsertingPreciselyOneWordCharacter) {\n                    tokenEndCharacter += 1;\n                }\n                else {\n                    continue;\n                }\n            }\n            else if (tokenDeltaLine === deltaLine && tokenStartCharacter < character && character < tokenEndCharacter) {\n                // 3. The token contains the insertion point\n                if (eolCount === 0) {\n                    // => just expand the end character\n                    tokenEndCharacter += firstLineLength;\n                }\n                else {\n                    // => cut off the token\n                    tokenEndCharacter = character;\n                }\n            }\n            else {\n                // 4. or 5.\n                if (tokenDeltaLine === deltaLine && tokenStartCharacter === character) {\n                    // 4. The token starts precisely at the insertion point\n                    // => grow the token (by keeping its start constant) only if inserting precisely one character that is a word character\n                    // => otherwise behave as in case 5.\n                    if (isInsertingPreciselyOneWordCharacter) {\n                        continue;\n                    }\n                }\n                // => the token must move and keep its size constant\n                if (tokenDeltaLine === deltaLine) {\n                    tokenDeltaLine += eolCount;\n                    // this token is on the line where the insertion is taking place\n                    if (eolCount === 0) {\n                        tokenStartCharacter += firstLineLength;\n                        tokenEndCharacter += firstLineLength;\n                    }\n                    else {\n                        const tokenLength = tokenEndCharacter - tokenStartCharacter;\n                        tokenStartCharacter = lastLineLength + (tokenStartCharacter - character);\n                        tokenEndCharacter = tokenStartCharacter + tokenLength;\n                    }\n                }\n                else {\n                    tokenDeltaLine += eolCount;\n                }\n            }\n            tokens[offset] = tokenDeltaLine;\n            tokens[offset + 1] = tokenStartCharacter;\n            tokens[offset + 2] = tokenEndCharacter;\n        }\n    }\n}\nexport class SparseLineTokens {\n    constructor(tokens) {\n        this._tokens = tokens;\n    }\n    getCount() {\n        return this._tokens.length / 4;\n    }\n    getStartCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 1];\n    }\n    getEndCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 2];\n    }\n    getMetadata(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 3];\n    }\n}\n"],"names":[],"sourceRoot":""}